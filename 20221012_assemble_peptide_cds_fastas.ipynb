{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from Bio import SeqIO\n",
    "from Bio import AlignIO   #, Align\n",
    "import shutil\n",
    "from ete3 import Tree, SeqMotifFace, TreeStyle, add_face_to_node, RectFace, NodeStyle, TextFace, AttrFace\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import diverse_yeast_tools as dyt\n",
    "\n",
    "base_dir = os.path.normpath('G:/My Drive/Crick_LMS/projects/diverse_yeasts/alphafold')\n",
    "divyeast_dir = os.path.normpath('C:/Users/heineib/Documents/GitHub/diverse_yeast')\n",
    "y1000plus_dir = os.path.normpath('C:/Users/heineib/Documents/GitHub/y1000plus_tools/data') + os.sep\n",
    "genomes_dir = os.path.normpath('G:/My Drive/Crick_LMS/external_data/genomes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spom: No official name, systematic_id or synonym for matmc_2 y1000_id=121_134\n",
      "Spom: No official name, systematic_id or synonym for SPCC622.05 y1000_id=121_2159\n",
      "Spom: No official name, systematic_id or synonym for SPAC4H3.12c y1000_id=121_2282\n",
      "Spom: No official name, systematic_id or synonym for meu1-1-1 y1000_id=121_2287\n",
      "Spom: No official name, systematic_id or synonym for sab14 y1000_id=121_2434\n",
      "Spom: No official name, systematic_id or synonym for SPBC36.13 y1000_id=121_2778\n",
      "Spom: No official name, systematic_id or synonym for SPAC1F8.09c.1 y1000_id=121_3125\n",
      "Spom: No official name, systematic_id or synonym for SPBC32F12.17 y1000_id=121_3368\n",
      "Spom: No official name, systematic_id or synonym for SPBC1685.12c y1000_id=121_3533\n",
      "Spom: No official name, systematic_id or synonym for SPCC417.04 y1000_id=121_3584\n",
      "Spom: No official name, systematic_id or synonym for SPMTR.04 y1000_id=121_3769\n",
      "Spom: No official name, systematic_id or synonym for SPMTR.03 y1000_id=121_3787\n",
      "Spom: No official name, systematic_id or synonym for SPCC188.05 y1000_id=121_3839\n",
      "Spom: No official name, systematic_id or synonym for chr3 y1000_id=121_3849\n",
      "Spom: No official name, systematic_id or synonym for ppr1.2 y1000_id=121_3929\n",
      "Spom: No official name, systematic_id or synonym for Tf2-10-pseudo y1000_id=121_4201\n",
      "Spom: No official name, systematic_id or synonym for SPAC27E2.13 y1000_id=121_4235\n",
      "Spom: No official name, systematic_id or synonym for matmc_1 y1000_id=121_426\n",
      "Spom: No official name, systematic_id or synonym for rgg8 y1000_id=121_4275\n",
      "Spom: No official name, systematic_id or synonym for ppr1.1 y1000_id=121_4515\n",
      "Spom: No official name, systematic_id or synonym for Tf2-13-pseudo y1000_id=121_4528\n",
      "Spom: No official name, systematic_id or synonym for mat1-m y1000_id=121_4547\n",
      "Spom: No official name, systematic_id or synonym for meu1-1-2 y1000_id=121_4559\n",
      "Spom: No official name, systematic_id or synonym for SPBC354.11c y1000_id=121_4585\n",
      "Spom: No official name, systematic_id or synonym for mat3-m y1000_id=121_4774\n",
      "Spom: No official name, systematic_id or synonym for sab10 y1000_id=121_4780\n",
      "Spom: No official name, systematic_id or synonym for chr1 y1000_id=121_4846\n",
      "Spom: No official name, systematic_id or synonym for SPCC1672.14 y1000_id=121_4989\n",
      "Spom: No official name, systematic_id or synonym for rpl35b y1000_id=121_521\n",
      "Spom: No official name, systematic_id or synonym for SPCC794.16 y1000_id=121_547\n",
      "Spom: No official name, systematic_id or synonym for SPAC1D4.07c y1000_id=121_640\n",
      "Spom: No official name, systematic_id or synonym for B22918-2 y1000_id=121_710\n",
      "gene_full not mapping to name that maps to systematic id SPAC110.05 systematic_id=SPAC110.06\n",
      "Spom: No official name, systematic_id or synonym for chr2 y1000_id=121_891\n",
      "Spom: No official name, systematic_id or synonym for tif35 y1000_id=121_937\n",
      "gene_full not mapping to name that maps to systematic id SPBC713.13 systematic_id=SPBC713.14c\n"
     ]
    }
   ],
   "source": [
    "#Load main analysis file\n",
    "struct_analysis = pickle.load(open(base_dir + os.sep + os.path.normpath('Output/data/Filter_clusters.pkl'), 'rb'))\n",
    "\n",
    "#Filter_clusters was made using Nir's clustering data.  \n",
    "# Oliver said \"we have to drop C0 in Nir's data. It affects OG1380 Q07732 and OG4312 P38280 in S.cer (REF)\"\n",
    "#The old analysis file had slightly different clusters to drop. \n",
    "#struct_analysis = pickle.load(open(base_dir + os.sep + os.path.normpath('Output/data/Analysis_new_02.pkl'), 'rb'))\n",
    "#OG1004__Scer_AF-P20095-F1-model_v2 and OG1004__Scer_AF-P15938-F1-model_v2 are examples where the orthogroup divides into smaller groups. 1603 \n",
    "#While making trees, found that OG1603 P25632 only had 3 sequences (A pombe and Cerevisiae sequence)\n",
    "\n",
    "\n",
    "\n",
    "#Load original sequence file, and make dictionary of gene_id to fasta header and gene_id to peptide sequence\n",
    "#Read in Sequence File, extract all names make dict of seq_alignment sequences\n",
    "selected_proteins = SeqIO.parse(base_dir +os.sep +  'selected_proteins.fasta', 'fasta')\n",
    "selected_proteins_headers = {}\n",
    "selected_proteins_seqs = {}\n",
    "for record in selected_proteins: \n",
    "    selected_proteins_headers[record.id] = record.description\n",
    "    selected_proteins_seqs[record.id] = str(record.seq)\n",
    "\n",
    "#Load peptide sequences for model species, make dictionary from gene id to peptide sequence\n",
    "model_protein_dict = {}\n",
    "for spec_abbrev in ['Scer', 'Spom', 'Calb']: \n",
    "    model_protein_dict[spec_abbrev] = dyt.load_model_protein_dict(spec_abbrev)\n",
    "    \n",
    "\n",
    "#ID Mapping for model species\n",
    "#Lookup from gene_id to y1000_id \n",
    "gene_id_2_y1000_id = dyt.load_model_gene_id_2_y1000_id()\n",
    "\n",
    "#swissprot_id_2_gene_id = dyt.load_model_swissprot_id_2_gene_id()\n",
    "swissprot_id_2_gene_id = dyt.load_model_swissprot_id_2_gene_id()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We want to filter these out:   \n",
    "#OG1380_REF_Scer_AF-Q07732-F1-model_v2\n",
    "\n",
    "This is from OG1380 which had two reference structures\n",
    "\n",
    "110_4710, YDL238C, Q07729, GUD1\n",
    "110_1500, YDL239C, Q07732, ADY3\n",
    "\n",
    "110_1500 (Q07732) didn't align to any other structures in the orthogroup and I think that one was wrongly assigned.  Also it's paralog, YNL225C, CNM67, 110_3851 wasn't include in the orthogroup which is another red flag.  Also a bit strange that the two genes are next to each other on the genome, and that they are separated in the list of orthoMCL output (see below)\n",
    "\n",
    "we keep: OG1380_REF_Scer_AF-Q07729-F1-model_v2\n",
    "\n",
    "\n",
    "#OG4312_REF_Scer_AF-P38280-F1-model_v2\n",
    "\n",
    "This is a similar situation: \n",
    "\n",
    "110_5464, YBR148W, P38280,  YSW1 \n",
    "110_2373, YBR149W, P38115,  ARA1\n",
    "\n",
    "YS1 also has a paralog, (SPO21, \n",
    "YOL091W,110_5868) which doesn't appear in the orthogroup.  \n",
    "\n",
    "We keep  OG4312_REF_Scer_AF-P38115-F1-model_v2\n",
    "\n",
    "Here are the full orthogroups: \n",
    "\n",
    "\n",
    "OrthoMCL output \n",
    "OG1380: 0_7979 100_4253 101_3817 102_6062 103_5437 104_348 105_1180 106_5111 107_3454 108_2387 109_4239 10_2835 110_4710 111_1387 112_1650 113_718 114_4120 115_4109 116_4617 117_3524 118_3724 119_4044 11_2137 120_5835 121_2481 122_4884 123_5112 124_2101 125_3038 126_2404 127_4095 128_109 129_1560 12_1581 130_3367 131_1184 133_455 134_1588 135_3929 136_2960 137_2455 138_145 139_5439 13_2807 140_498 141_201 142_6286 143_5626 144_4382 145_4265 146_727 147_505 148_1666 149_2724 14_4430 150_1853 151_1750 152_1866 153_4807 154_5081 155_4631 156_4181 157_57 158_4406 159_3477 15_3825 160_1725 161_1345 162_4652 162_7685 163_3 164_1136 165_502 166_1085 167_3652 168_554 169_1185 16_442 170_976 171_2915 172_569 173_3649 174_2546 175_880 176_2935 177_4190 178_1430 179_1349 17_4470 180_1014 181_1221 182_1868 183_3094 184_2142 185_2479 186_7321 187_2997 188_3855 189_2713 18_4780 190_3057 191_11 192_1922 193_1953 194_5564 195_6999 196_3875 197_1074 198_1333 199_1654 19_2192 1_2320 200_5575 201_5015 202_3724 203_3378 204_3646 205_1851 206_1466 207_4698 208_866 209_1593 20_5171 210_5311 211_280 212_7439 213_1477 214_4903 215_6975 216_7879 217_1061 218_2201 219_612 21_3250 220_3150 221_1087 222_4980 223_3153 223_4919 224_3212 225_989 226_988 227_1061 228_288 229_3297 22_1871 230_5045 231_1857 232_1487 233_3318 233_643 234_1770 235_4216 236_1754 237_765 238_2593 238_536 239_3845 23_1723 240_4053 241_2332 242_3797 243_1657 244_422 245_1161 245_5322 246_12140 246_1257 246_1672 247_3550 248_946 249_3487 24_4840 250_1941 251_2697 252_2887 253_4804 254_109 255_4340 256_224 257_7103 258_36 259_2658 25_413 260_4371 261_2906 262_3266 263_356 264_2359 265_5094 266_3343 267_5453 268_1634 269_1392 26_2796 270_551 271_868 272_2471 273_2713 274_1637 275_1926 276_2162 277_3080 278_1254 279_5551 27_4285 280_5432 281_1196 283_4835 284_1046 285_3881 286_3199 287_1328 288_4607 289_4174 28_4523 290_626 292_4358 293_2170 294_3509 295_4648 296_4410 297_2892 298_1950 299_720 29_362 2_1802 300_2514 301_4895 302_1651 303_870 304_4414 305_3871 306_4543 307_2904 308_2445 309_218 30_5659 310_5143 311_1972 312_5610 313_347 314_3162 315_69 316_4515 317_5489 318_4838 319_1755 31_2778 31_3568 320_3083 321_2765 322_2192 323_86 324_707 325_5308 326_5838 327_1459 328_1140 329_3023 32_296 330_4719 331_3826 332_6309 333_2654 334_2779 335_627 336_4011 337_583 338_1331 339_4690 33_5843 340_5308 341_3165 342_1249 34_2841 35_4891 36_2559 37_2926 3_5729 42_1786 43_4147 44_1489 45_1613 46_3255 47_3991 49_2833 4_1857 50_1856 51_3157 52_80 53_47 54_2330 55_972 56_2062 57_1797 58_2309 59_4800 5_4710 60_906 61_920 62_4929 63_3584 64_2292 65_4669 66_7500 67_2789 69_664 6_1150 6_3153 6_5015 70_4894 71_1931 72_559 73_1395 74_2269 75_1603 76_3820 77_3910 78_5100 78_5836 79_3935 80_2013 81_3193 82_3677 83_2710 84_966 85_4866 86_5853 87_4990 88_3268 89_3822 8_6737 90_4378 91_3509 92_4498 93_1615 94_902 95_3852 96_3202 97_1100 98_3151 99_2311 9_4542 22_1437 290_403 172_187 15_1499 228_234 230_650 234_1916 103_4451 160_4492 189_1353 226_883 229_5558 231_2640 233_5082 235_2552 236_3821 237_637 238_4636 241_4669 284_3996 53_1753 53_328 110_1500 114_2713 232_3250 190_5056\n",
    "\n",
    "OG4312: 105_2440 15_5119 193_1462 233_2728 234_2443 235_973 240_5182 243_3685 277_2923 313_3735 100_271 101_2850 103_1114 106_5303 107_3045 109_1518 110_2373 111_676 112_1530 113_1707 113_2131 114_3654 115_4038 116_2995 119_2420 11_2509 120_3094 123_2102 123_2865 124_6051 127_5480 128_3721 12_3502 137_1571 139_6065 140_3429 146_1919 147_4561 148_1207 149_5134 14_4455 150_870 151_3741 152_537 153_2758 154_1802 155_5253 156_1145 158_34 159_71 160_126 161_5979 162_6883 163_3900 164_1861 165_2447 166_1617 168_457 16_1928 170_3358 172_4044 173_4599 176_3544 17_3425 180_509 181_1646 182_3615 183_4858 184_480 185_3280 187_1410 189_2923 18_147 191_4898 194_2814 198_5467 1_972 208_880 217_814 219_2709 224_3967 225_2967 226_1456 226_4544 228_1171 229_4717 230_5059 231_1276 232_1991 233_480 235_6 236_2319 237_715 23_3815 241_1711 244_4654 245_5483 246_9337 247_3900 24_2220 250_2452 251_4498 252_2172 254_2371 255_5001 256_5031 257_845 258_3257 259_195 260_1573 261_2122 262_1620 262_737 263_4387 264_4299 265_3620 266_1967 267_2120 268_1817 269_1055 270_2837 271_3037 273_2193 273_4190 274_1228 275_3604 276_828 27_1445 280_1353 283_1624 284_1717 285_3498 285_5154 286_3837 286_4325 287_2223 288_900 289_2400 28_3994 290_5258 293_3141 294_1897 295_988 299_4107 29_604 2_1778 2_74 304_4300 306_5473 307_3035 308_1569 309_990 30_5633 311_2849 312_5969 314_5133 315_3625 316_4563 317_2510 318_4080 319_1452 320_4268 321_3993 323_3201 325_4065 326_5211 327_4234 328_122 329_5516 32_2325 330_277 334_4167 335_864 336_3847 338_4948 340_3541 341_2212 342_2290 34_1272 35_3004 36_2114 37_2895 44_2343 45_2204 46_371 47_3261 48_2133 49_2789 50_199 51_4613 53_621 55_2664 56_4914 57_2283 59_1088 60_2628 61_144 62_590 63_58 64_1023 65_846 67_3819 91_4700 92_1006 99_1227 9_369 139_1772 142_2792 144_2332 172_1273 196_4330 201_442 241_2921 244_4204 257_4200 292_3284 292_735 296_5543 297_3403 340_1334 140_4847 160_2176 162_6036 162_6042 162_6389 230_840 234_522 245_4850 246_6737 246_9401 268_2639 53_3165 53_3434 201_3037 162_2583 245_6684 239_5185 258_3763 336_5209 46_2479 58_1410 99_412 127_4388 203_3682 245_923 27_3713 140_4831 43_605 109_2478 110_5464 111_4365 112_1416 143_5447 277_6609 202_1342 126_6065 124_2222 233_2217 9_2186 144_2569 253_2721 199_2141 162_7100 226_5057\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This step seems unnecessary - could just go from original fasta file? Also filtering of those OGs is done at the clustering step.  \n",
    "\n",
    "##Instead of cycling through the proteins that came out of Oliver's runs, can cycle over the original FASTAs I provided. \n",
    "#This will mean that there will be some included whose sequences did not get calculated, but that will get filtered out after the alignment step. \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saccharomyces_cerevisiae',\n",
       " 'debaryomyces_hansenii',\n",
       " 'wickerhamomyces_anomalus',\n",
       " 'lachancea_thermotolerans',\n",
       " 'kazachstania_naganishii',\n",
       " 'kluyveromyces_marxianus',\n",
       " 'yHMPu5000034957_hanseniaspora_osmophila_160519',\n",
       " 'geotrichum_candidum',\n",
       " 'zygosaccharomyces_rouxii',\n",
       " 'candida_albicans',\n",
       " 'candida_tropicalis',\n",
       " 'kluyveromyces_lactis',\n",
       " 'komagataella_pastoris',\n",
       " 'schizosaccharomyces_pombe',\n",
       " 'vanderwaltozyma_polyspora',\n",
       " 'torulaspora_delbrueckii',\n",
       " 'eremothecium_gossypii',\n",
       " 'ascoidea_rubescens',\n",
       " 'cyberlindnera_jadinii',\n",
       " 'ogataea_parapolymorpha',\n",
       " 'pachysolen_tannophilus',\n",
       " 'yHMPu5000034604_sporopachydermia_lactativora_160519',\n",
       " 'alloascoidea_hylecoeti',\n",
       " 'candida_apicola',\n",
       " 'yarrowia_lipolytica',\n",
       " 'tortispora_caseinolytica',\n",
       " 'lipomyces_starkeyi']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make proteins_present_by_spec JSON file listing proteins we want to consider for each species. \n",
    "# This json is keyed on species and has elements\n",
    "#[name_orig,gene_id,y1000_id,swissprot_id,source]\n",
    "\n",
    "species_table = pd.read_csv(base_dir + os.sep + os.path.normpath('selected_proteins/species_selection/species_selection.csv'))\n",
    "specs = list(species_table.loc[species_table['Load']=='Y']['original_genome_id'])\n",
    "proteins_present_by_spec = {spec: [] for spec in specs}\n",
    "\n",
    "modelspec_params = {'Scer':('saccharomyces_cerevisiae'), \n",
    "                    'Calb':('candida_albicans'), \n",
    "                    'Spom':('schizosaccharomyces_pombe')\n",
    "                   }\n",
    "\n",
    "proteins_present_by_spec_fname = base_dir + os.sep + os.path.normpath('selected_proteins/selected_protein_ids.json')\n",
    "\n",
    "\n",
    "#Cycle through selected_proteins_modelorgs.fasta: \n",
    "\n",
    "selected_proteins = SeqIO.parse(base_dir + os.sep + os.path.normpath('selected_proteins/selected_proteins.fasta'), \"fasta\")\n",
    "\n",
    "for record in selected_proteins: \n",
    "\n",
    "    (spec, og, y1000_id) = record.id.split('__')\n",
    "\n",
    "    header_dict = {}\n",
    "    for item in record.description.split(' ')[1:]: \n",
    "        key,val = item.split('=')\n",
    "        header_dict[key] = val\n",
    "\n",
    "    source = header_dict['source']\n",
    "    if source=='uniprot':\n",
    "        swissprot_id = header_dict['gene_full'].split('|')[1]\n",
    "    elif source=='shen':\n",
    "        swissprot_id = None\n",
    "\n",
    "    proteins_present_by_spec[spec].append((record.id,None,y1000_id,swissprot_id, source))\n",
    "    \n",
    "selected_proteins_modelorgs = SeqIO.parse(base_dir + os.sep + os.path.normpath('selected_proteins/selected_proteins_modelorgs.fasta'), \"fasta\")\n",
    "\n",
    "for record in selected_proteins_modelorgs: \n",
    "\n",
    "    gene_id = record.id\n",
    "    header_dict = {}\n",
    "    for item in record.description.split(' ')[1:]: \n",
    "        key,val = item.split('=')\n",
    "        header_dict[key] = val\n",
    "    \n",
    "    proteins_present_by_spec[header_dict['species']].append(( header_dict['af2_id'],gene_id,header_dict['y1000_id'], header_dict['uniprot_id'],'af2'))\n",
    "\n",
    "\n",
    "with open(proteins_present_by_spec_fname, 'w') as f:\n",
    "    json.dump(proteins_present_by_spec, f, sort_keys=True, indent=4 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'og': 'OG2365',\n",
       " 'species': 'candida_albicans',\n",
       " 'uniprot_id': 'Q9Y872',\n",
       " 'af2_id': 'Calb_AF-Q9Y872-F1-model_v2',\n",
       " 'y1000_id': '12_1859'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This might be useful to do Oliver's structural alignments, but not useful for the proteins_present_by_spec json, as that is calculated from original data above\n",
    "\n",
    "# #Filter original structural alignments to remove poorly aligned structures.  \n",
    "# #Also include metadata from original species selection fasta and add metadata for model species. \n",
    "# # base_dir/selected_proteins.fasta\n",
    "# #\n",
    "# #\n",
    "# # Make a protein fasta for each alignment from orignal sequence and with model species sequences\n",
    "# #\n",
    "# # Make a dictionary of lists of each protein present in each species - save as a .json\n",
    "# # This json is keyed on species and has elements\n",
    "# #[name_orig,gene_id,y1000_id,swissprot_id,source]\n",
    "\n",
    "# #Filter based on above errors to Orthogroup Assignment\n",
    "# og_ref_filter_list = ['OG1380_REF_Scer_AF-Q07732-F1-model_v2','OG4312_REF_Scer_AF-P38280-F1-model_v2' ]\n",
    "\n",
    "# species_table = pd.read_csv(base_dir + os.sep + 'species_selection.csv')\n",
    "# specs = list(species_table.loc[species_table['Load']=='Y']['original_genome_id'])\n",
    "# proteins_present_by_spec = {spec: [] for spec in specs}\n",
    "\n",
    "# modelspec_params = {'Scer':('saccharomyces_cerevisiae'), \n",
    "#                     'Calb':('candida_albicans'), \n",
    "#                     'Spom':('schizosaccharomyces_pombe')\n",
    "#                    }\n",
    "# proteins_present_by_spec_fname = base_dir + os.sep + 'selected_protein_ids.json'\n",
    "\n",
    "\n",
    "# for fasta_fname in os.listdir(base_dir + os.sep +  os.path.normpath('msas\\structural\\FASTA') + os.sep  ):\n",
    "#     #fasta_fname = 'OG1004_REF_Scer_AF-P15938-F1-model_v2.FASTA'\n",
    "    \n",
    "#     if not(fasta_fname in [name + '.FASTA' for name in og_ref_filter_list]): \n",
    "    \n",
    "#         fasta_fname_base = fasta_fname.split('.')[0]\n",
    "\n",
    "#         seqs_to_include = struct_analysis[fasta_fname.split('.')[0]]['Files to be included']\n",
    "\n",
    "#         fname_struct_aln_orig = base_dir + os.sep +  os.path.normpath('msas\\structural\\FASTA\\\\' + fasta_fname)   # os.path.normpath('msas\\FILES_ogs_pep_aligned\\\\' + og + '.mfaa.mafft')\n",
    "#         fname_struct_aln_filt_out = base_dir + os.sep + os.path.normpath('msas\\structural\\\\fasta_filt\\\\' + fasta_fname_base + '.struct_filt.fasta')\n",
    "#         fname_proteome = base_dir + os.sep + os.path.normpath('og_sequences\\proteome\\\\' + fasta_fname_base + '.pep.fasta')\n",
    "\n",
    "#         #Read in dictionary of ref name map to sequence name\n",
    "#         struct_align = AlignIO.read(fname_struct_aln_orig, 'fasta')\n",
    "#         with open(fname_struct_aln_filt_out , 'w') as f_out_filt:\n",
    "#             with open(fname_proteome, 'w') as f_out_prot: \n",
    "#                 for record in struct_align: \n",
    "#                     structure_imported = False\n",
    "#                     name_orig = record.id    \n",
    "\n",
    "#                     #Check if name in ref sequence (S.cer, C.alb, and S. pom) + convert\n",
    "#                     if name_orig.split('_')[0] in set(['Scer', 'REF', 'Calb', 'Spom']):\n",
    "#                         structure_imported = True\n",
    "#                         if name_orig.split('_')[0] == 'REF': \n",
    "#                             spec_abbrev = name_orig.split('_')[1]\n",
    "#                             swissprot_id = name_orig.split('_')[2].split('-')[1]\n",
    "#                         else: \n",
    "#                             spec_abbrev = name_orig.split('_')[0]\n",
    "#                             swissprot_id = name_orig.split('_')[1].split('-')[1]\n",
    "\n",
    "#                         (spec) = modelspec_params[spec_abbrev]\n",
    "#                         gene_id = swissprot_id_2_gene_id[spec_abbrev][swissprot_id]\n",
    "#                         if spec_abbrev == 'Spom':\n",
    "#                             y1000_id = 'None'\n",
    "#                         else: \n",
    "#                             #spec_old = spec_abbrev_dict[spec_abbrev]\n",
    "#                             y1000_id = gene_id_2_y1000_id[spec_abbrev][gene_id]\n",
    "\n",
    "#                     else: \n",
    "#                         (spec, og, y1000_id) = name_orig.split('__')\n",
    "\n",
    "\n",
    "#                     #Filter by structural clusters within OGs based on Nir's analysis\n",
    "#                     if name_orig in seqs_to_include: \n",
    "\n",
    "#                         #Extract sequence from original peptide fasta\n",
    "\n",
    "#                         if structure_imported: \n",
    "#                             prot_seq = model_protein_dict[spec_abbrev][gene_id]\n",
    "#                             L = len(prot_seq)\n",
    "#                             header = '>' + name_orig + ' source=af2  gene_full=' + gene_id +' y1000_id=' + y1000_id + ' L=' + str(L) + '\\n' \n",
    "\n",
    "#                             proteins_present_by_spec[spec].append((name_orig,gene_id,y1000_id,swissprot_id,'af2'))\n",
    "\n",
    "\n",
    "#                         else: \n",
    "#                             header_dict = {}\n",
    "#                             header_raw =selected_proteins_headers[name_orig] \n",
    "#                             for item in header_raw.split(' ')[1:]: \n",
    "#                                 key,val = item.split('=')\n",
    "#                                 header_dict[key] = val\n",
    "\n",
    "#                             source = header_dict['source']\n",
    "#                             if source=='uniprot':\n",
    "#                                 swissprot_id = header_dict['gene_full'].split('|')[1]\n",
    "#                             elif source=='shen':\n",
    "#                                 swissprot_id = None\n",
    "\n",
    "#                             proteins_present_by_spec[spec].append((name_orig,None,y1000_id,swissprot_id, source))\n",
    "\n",
    "#                             prot_seq = selected_proteins_seqs[name_orig]\n",
    "#                             header = '>' + header_raw + '\\n'  \n",
    "\n",
    "\n",
    "#                         f_out_prot.write(header)\n",
    "#                         f_out_prot.write(prot_seq + '\\n')\n",
    "\n",
    "#                         f_out_filt.write(header)\n",
    "#                         f_out_filt.write(str(record.seq) + '\\n')\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "# # Save proteins_present_by_spec\n",
    "\n",
    "# #remove_duplicates\n",
    "# for spec in specs: \n",
    "#     proteins_present_by_spec[spec] = list(set(proteins_present_by_spec[spec]))\n",
    "\n",
    "# with open(proteins_present_by_spec_fname, 'w') as f:\n",
    "#     json.dump(proteins_present_by_spec, f, sort_keys=True, indent=4 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifies source of coding sequences for each species\n",
    "cds_params = { \n",
    "                 'saccharomyces_cerevisiae': {'modeldb': genomes_dir + os.sep + os.path.normpath('saccharomyces_cerevisiae/S288C_reference_genome_R64-2-1_20150113/orf_coding_all_R64-2-1_20150113.fasta') },\n",
    "                 #'schizosaccharomyces_pombe': {'af2': genomes_dir + os.sep + os.path.normpath('schizosaccharomyces_pombe/cds.fa')},\n",
    "                 'candida_albicans' : {'modeldb': genomes_dir + os.sep + os.path.normpath('candida_albicans/C_albicans_SC5314_A22_current_default_coding.fasta')}\n",
    "             }\n",
    "             \n",
    "    \n",
    "#shen_only                 \n",
    "shen_specs = [\n",
    "                 'kazachstania_naganishii',\n",
    "                 'geotrichum_candidum',\n",
    "                 'vanderwaltozyma_polyspora',                              \n",
    "                 'eremothecium_gossypii',\n",
    "                 'ascoidea_rubescens',\n",
    "                 'cyberlindnera_jadinii',\n",
    "                 'ogataea_parapolymorpha',\n",
    "                 'pachysolen_tannophilus',\n",
    "                 'yHMPu5000034604_sporopachydermia_lactativora_160519',\n",
    "                 'alloascoidea_hylecoeti',\n",
    "                 'candida_apicola',\n",
    "                 'yarrowia_lipolytica',\n",
    "                 'tortispora_caseinolytica',\n",
    "                 'lipomyces_starkeyi',\n",
    "                 #shen/uniprot_ncbi_genome\n",
    "                 'wickerhamomyces_anomalus',\n",
    "                 'yHMPu5000034957_hanseniaspora_osmophila_160519',\n",
    "                 'candida_tropicalis',\n",
    "                 #shen/uniprot_ncbi\n",
    "                 'zygosaccharomyces_rouxii',\n",
    "                 'debaryomyces_hansenii',\n",
    "                 'lachancea_thermotolerans',\n",
    "                 'kluyveromyces_marxianus',\n",
    "                 'kluyveromyces_lactis',\n",
    "                 'komagataella_pastoris',\n",
    "                 'torulaspora_delbrueckii'\n",
    "                  ]\n",
    "\n",
    "for spec in shen_specs: \n",
    "    cds_params[spec] = {'shen':y1000plus_dir + os.sep + os.path.normpath('shen_2018_data/0_332yeast_genomes/332_genome_annotations/cds/' + spec +'.max.cds')}\n",
    "\n",
    "#uniprot_ncbi_genome\n",
    "uniprot_ncbi_genome_specs = [\n",
    "                 'wickerhamomyces_anomalus',\n",
    "                 'yHMPu5000034957_hanseniaspora_osmophila_160519',\n",
    "                 'candida_tropicalis'\n",
    "                  ]\n",
    "\n",
    "for spec in uniprot_ncbi_genome_specs: \n",
    "    cds_params[spec]['uniprot_ncbi_genome'] = genomes_dir + os.sep + os.path.normpath('diverse_yeast/ncbi_genomes_coding_seq/' + spec + '/cds.fasta')\n",
    "\n",
    "    \n",
    "#uniprot_ncbi\n",
    "uniprot_ncbi_specs = [\n",
    "                 'zygosaccharomyces_rouxii',\n",
    "                 'debaryomyces_hansenii',\n",
    "                 'lachancea_thermotolerans',\n",
    "                 'kluyveromyces_marxianus',\n",
    "                 'kluyveromyces_lactis',\n",
    "                 'komagataella_pastoris', \n",
    "                 'schizosaccharomyces_pombe'\n",
    "                     ]\n",
    "\n",
    "for spec in uniprot_ncbi_specs: \n",
    "    if spec in cds_params.keys():\n",
    "        cds_params[spec]['uniprot_ncbi'] = genomes_dir + os.sep + os.path.normpath('diverse_yeast/ncbi_coding_seq/'+ spec + '/cds.fasta')\n",
    "    else: \n",
    "        cds_params[spec] = {'uniprot_ncbi': genomes_dir + os.sep + os.path.normpath('diverse_yeast/ncbi_coding_seq/'+ spec + '/cds.fasta')}\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load proteins_present_by_spec\n",
    "\n",
    "proteins_present_by_spec_fname = base_dir + os.sep + os.path.normpath('selected_proteins/selected_protein_ids.json')\n",
    "    \n",
    "with open(proteins_present_by_spec_fname, 'r') as f:\n",
    "    proteins_present_by_spec = json.load(f) \n",
    "    \n",
    "#proteins_present_by_spec['kluyveromyces_lactis']\n",
    "#['REF_Scer_AF-P16661-F1-model_v2', 'YBR110W', '110_477', 'P16661']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeldb\n",
      "saccharomyces_cerevisiae\n",
      "candida_albicans\n",
      "shen\n",
      "kazachstania_naganishii\n",
      "geotrichum_candidum\n",
      "vanderwaltozyma_polyspora\n",
      "eremothecium_gossypii\n",
      "ascoidea_rubescens\n",
      "cyberlindnera_jadinii\n",
      "ogataea_parapolymorpha\n",
      "pachysolen_tannophilus\n",
      "yHMPu5000034604_sporopachydermia_lactativora_160519\n",
      "alloascoidea_hylecoeti\n",
      "candida_apicola\n",
      "yarrowia_lipolytica\n",
      "tortispora_caseinolytica\n",
      "lipomyces_starkeyi\n",
      "wickerhamomyces_anomalus\n",
      "yHMPu5000034957_hanseniaspora_osmophila_160519\n",
      "candida_tropicalis\n",
      "zygosaccharomyces_rouxii\n",
      "debaryomyces_hansenii\n",
      "lachancea_thermotolerans\n",
      "kluyveromyces_marxianus\n",
      "kluyveromyces_lactis\n",
      "komagataella_pastoris\n",
      "torulaspora_delbrueckii\n",
      "uniprot_ncbi\n",
      "zygosaccharomyces_rouxii\n",
      "debaryomyces_hansenii\n",
      "lachancea_thermotolerans\n",
      "kluyveromyces_marxianus\n",
      "kluyveromyces_lactis\n",
      "komagataella_pastoris\n",
      "schizosaccharomyces_pombe\n",
      "uniprot_ncbi_genome\n",
      "wickerhamomyces_anomalus\n",
      "A0A1E3P784 not found in wickerhamomyces_anomalus uniprot_ncbi_genome cds file\n",
      "yHMPu5000034957_hanseniaspora_osmophila_160519\n",
      "candida_tropicalis\n"
     ]
    }
   ],
   "source": [
    "#Print CDS for selected proteins from each source by species\n",
    "\n",
    "for cds_source in ['modeldb', 'shen','uniprot_ncbi', 'uniprot_ncbi_genome']: \n",
    "\n",
    "    print(cds_source)\n",
    "    #cds_source = 'uniprot_ncbi'\n",
    "\n",
    "    for spec, cds_params_spec in cds_params.items():\n",
    "        #spec = 'schizosaccharomyces_pombe'\n",
    "        #cds_params_spec = cds_params[spec]\n",
    "\n",
    "        if cds_source in cds_params_spec.keys():\n",
    "            print(spec)\n",
    "            cds_out_fname = base_dir + os.sep + os.path.normpath('selected_proteins/cds/' + spec+'__'+ cds_source + '.fasta')\n",
    "            #Load CDS file\n",
    "            cds_fasta = SeqIO.parse(cds_params_spec[cds_source], 'fasta')\n",
    "\n",
    "            #make dictionary keyed on ID of cds seq\n",
    "            cds_fasta_dict = {}\n",
    "            for record in cds_fasta:\n",
    "                cds_fasta_dict[record.id] = str(record.seq)\n",
    "\n",
    "            #for shen genomes, make lookup for y1000_id\n",
    "            #Load y1000_id gene_full lookup\n",
    "            y1000_id_table = pd.read_csv(y1000plus_dir + os.sep + os.path.normpath('y1000plus_tools_data/y1000plus/id_lookups/' + spec + '.csv'))\n",
    "            y1000_id_2_gene_full = dict(zip(y1000_id_table['y1000_id'],y1000_id_table['gene_full']))            \n",
    "\n",
    "            proteins_present = proteins_present_by_spec[spec]\n",
    "\n",
    "            with open(cds_out_fname,'w') as f_cds_out: \n",
    "                for (name_orig,gene_id,y1000_id,uniprot_id,source) in proteins_present:\n",
    "                    if cds_source=='modeldb': \n",
    "                        try:\n",
    "                            f_cds_out.write('>' + name_orig+ ' source=' + cds_source + 'source_id=' + gene_id + '\\n')\n",
    "                            f_cds_out.write(cds_fasta_dict[gene_id] + '\\n')\n",
    "                        except KeyError:\n",
    "                            print(gene_id + 'not found in ' + spec + ' ' + cds_source + ' cds file')\n",
    "\n",
    "                    if cds_source=='shen': \n",
    "                        if source=='shen':\n",
    "                            try:\n",
    "                                gene_full_cds = y1000_id_2_gene_full[y1000_id] + '-mRNA-1'\n",
    "                                f_cds_out.write('>' + name_orig+ ' source=' + cds_source + ' source_id=' + gene_full_cds + '\\n')\n",
    "                                f_cds_out.write(cds_fasta_dict[gene_full_cds] + '\\n')\n",
    "                            except KeyError:\n",
    "                                print(gene_full +  ' not found in ' + spec + ' ' + cds_source + ' cds file')\n",
    "\n",
    "                    if cds_source=='uniprot_ncbi_genome':\n",
    "                        if source=='uniprot':\n",
    "                            try:\n",
    "                                f_cds_out.write('>' + name_orig + ' source=' + cds_source + ' source_id=' + uniprot_id + '\\n')\n",
    "                                f_cds_out.write(cds_fasta_dict[uniprot_id] + '\\n')\n",
    "                            except KeyError:\n",
    "                                print(uniprot_id +  ' not found in ' + spec + ' ' + cds_source + ' cds file')\n",
    "\n",
    "                    if cds_source=='uniprot_ncbi':\n",
    "                        if ((source=='uniprot') | ((source=='af2') & (spec=='schizosaccharomyces_pombe'))):\n",
    "                            try:\n",
    "                                f_cds_out.write('>' + name_orig + ' source=' + cds_source + ' source_id=' + uniprot_id + '\\n')\n",
    "                                f_cds_out.write(cds_fasta_dict[uniprot_id] + '\\n')\n",
    "                            except KeyError:\n",
    "                                print(uniprot_id +  ' not found in ' + spec + ' ' + cds_source + ' cds file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename files for Nir's clusters to match main names\n",
    "## Build CDS alignments for Nir's clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decided not to go with clusters.pkl that Oliver sent because that didn't match my file.  \n",
    "#To load that data, do:\n",
    "#clusters = pickle.load(open(base_dir + os.sep + os.path.normpath('msas/structural/tm_align/clustering/clusters.pkl'), 'rb'))\n",
    "#Of the small clusters there were the 14 C0 clusters.  It looks like all these were removed from this original file. \n",
    "\n",
    "#Instead starting from documents that Nir left at: https://charitede-my.sharepoint.com/personal/nir_cohen_charite_de/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fnir%5Fcohen%5Fcharite%5Fde%2FDocuments%2Fortho%5Faligment%2Fsub%5Fortho%5Fre%5Fclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.read_csv(base_dir + os.sep + os.path.normpath('msas/structural/tm_align/clustering/clusters_0.15.csv'), index_col=0)\n",
    "#assemble dictionary of OG_cluster to list of proteins\n",
    "\n",
    "cluster_msa_base = base_dir + os.sep + os.path.normpath('msas/structural/tm_align/fasta') + os.sep\n",
    "\n",
    "clusters = {}\n",
    "clusters_ref = {}\n",
    "\n",
    "for OG, clust in zip(clusters_df['ortho_group'], clusters_df['cluster']): \n",
    "    cluster_seqs = SeqIO.parse(cluster_msa_base + OG + clust + '.fa', 'fasta')\n",
    "    seq_list = []\n",
    "    N_refs = 0\n",
    "    for record in cluster_seqs: \n",
    "        seq_list.append(record.id)\n",
    "        if len(record.description.split('*'))==2: #The line with the * is assigned by tm_align as the reference for the alignment\n",
    "            clusters_ref[OG + '_' + clust] = record.id\n",
    "            N_refs = N_refs+1\n",
    "    clusters[OG + '_' + clust] = seq_list\n",
    "    assert N_refs==1, 'More than one reference cluster ' + OG + '_' + clust\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 479 nonzero clusters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'N clusters')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clust_lengths = []\n",
    "\n",
    "#File to list small clusters (less than 3 proteins) that are filtered out\n",
    "small_cluster_filt_fname = base_dir + os.sep + os.path.normpath('msas/structural/tm_align/clustering/small_clusters.txt')\n",
    "\n",
    "#File to list clusters with no SC proteins\n",
    "sc_cluster_filt_fname = base_dir + os.sep + os.path.normpath('msas/structural/tm_align/clustering/non_sc_clusters.txt')\n",
    "\n",
    "\n",
    "with(open(small_cluster_filt_fname, 'w')) as f_small:\n",
    "    with(open(sc_cluster_filt_fname, 'w')) as f_no_sc:\n",
    "        f_small.write('OG_cluster\\tcluster_genes\\n')\n",
    "        f_no_sc.write('OG_cluster\\tcluster_size\\n')\n",
    "        for og_clust, cluster in clusters.items():\n",
    "            no_sc_clust = True\n",
    "            clust_len = len(cluster)\n",
    "            clust_lengths.append(clust_len)\n",
    "            if clust_len>0: \n",
    "\n",
    "                if clust_len<3: \n",
    "                    f_small.write(og_clust+'\\t[' + \",\".join(cluster) + ']\\n' )\n",
    "\n",
    "                for seq in cluster: \n",
    "                    if seq.split('_')[0]=='REF':  #This means there is an S.cer protein present\n",
    "                        no_sc_clust = False\n",
    "\n",
    "                if no_sc_clust: \n",
    "                    f_no_sc.write(og_clust + '\\t' + str(clust_len) + '\\n')\n",
    "                \n",
    "            \n",
    "clust_count = Counter(clust_lengths)\n",
    "\n",
    "print('There are ' + str(len(clusters) - clust_count[0]) + ' nonzero clusters')\n",
    "\n",
    "sizes = []\n",
    "nclusts = []\n",
    "for size, nclust in clust_count.items(): \n",
    "    if size>0:\n",
    "        sizes.append(size)\n",
    "        nclusts.append(nclust)\n",
    "\n",
    "#Plot Histogram of all nonzero clusters\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(sizes, nclusts)\n",
    "ax.set_xlabel('Cluster Size')\n",
    "ax.set_ylabel('N clusters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of clusters that don't have an SC protein but have more than a few proteins present.  \n",
    "no_sc_clusters = pd.read_table(sc_cluster_filt_fname)\n",
    "no_sc_clusters_filt = no_sc_clusters[no_sc_clusters['cluster_size']>2].sort_values(by='cluster_size', ascending=False)\n",
    "\n",
    "#'OG5006_C1' is strange - 5 different proteins from K.mar.  The S. cer orthoglog is COB, a mitochondrial encoded Cytochrome B Oxidase, as well as an overlapping transcript, BI3 which is a Maturase which mediates splicing of an intron.  \n",
    "# OG4755_C1 also has many K.mar genes and is COX2\n",
    "# OG5438 is ortholog of BIO3 (biotin synthesis)\n",
    "# OG5722 is ADH4 and has duplicates in a. hylecoeti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a file to list all the clusters.  Also assigns first reference structure in a cluster as the representative (so we don't have redundant clusters)\n",
    "#If there is no S. cer protein present it picks the tm_align assigned reference structure (which had a *) for the name - see clusters_ref\n",
    "cluster_name_map = {}\n",
    "with open(base_dir + os.sep + os.path.normpath('msas/structural/tm_align/clustering/cluster_mapping.csv'), 'w') as f_out: \n",
    "    f_out.write('primary_id,og_clust,cluster_rep,no_sc\\n')\n",
    "    for og_clust, cluster in clusters.items():\n",
    "        if len(cluster)>0:\n",
    "            og, clust = og_clust.split('_')\n",
    "            if og_clust in set(no_sc_clusters_filt['OG_cluster']):  #For clusters with no S. cer reference ##Use line with star as a reference\n",
    "                seq = clusters_ref[og_clust]\n",
    "                cluster_name_map[seq]=og_clust\n",
    "                ref = seq.split('.')[0]\n",
    "                f_out.write(og+ '_' + ref + ',' + og_clust + ',1,TRUE\\n')\n",
    "            else: #For clusters that have an S.cer reference\n",
    "                cluster_rep = 1\n",
    "                for seq in cluster: #lists same cluster multiple times if there are multiple S.cer refs present\n",
    "                    if seq.split('_')[0]=='REF':\n",
    "                        cluster_name_map[seq] = og_clust \n",
    "                        ref = seq.split('.')[0]\n",
    "                        f_out.write(og+ '_' + ref + ',' + og_clust + ',' + str(cluster_rep) + ',FALSE\\n')\n",
    "                        cluster_rep = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the TM-align structural alignments to match our other names.  \n",
    "pep_seq_dir = base_dir + os.sep + os.path.normpath('og_sequences/proteome')\n",
    "tm_align_dir = base_dir + os.sep +  os.path.normpath('msas/structural/tm_align')\n",
    "clust_align_dir = tm_align_dir + os.sep + 'fasta' + os.sep\n",
    "clust_align_rename_dir = tm_align_dir + os.sep + 'fasta_renamed' + os.sep\n",
    "#clust_align_rename_all_dir = tm_align_dir + os.sep + 'fasta_renamed_all' + os.sep\n",
    "\n",
    "cluster_mapping = pd.read_csv(tm_align_dir + os.sep + os.path.normpath('clustering/cluster_mapping.csv'))\n",
    "cluster_mapping_dict = dict(zip(cluster_mapping['primary_id'], cluster_mapping['og_clust']))\n",
    "\n",
    "\n",
    "#Option 1:  File only for representative clusters: \n",
    "for (ind, (og_ref,og_clust, cluster_rep, no_sc)) in cluster_mapping.iterrows():\n",
    "    if cluster_rep == 1: \n",
    "        og, clust = og_clust.split('_')\n",
    "        shutil.copyfile(clust_align_dir + og+clust + '.fa', clust_align_rename_dir + og_ref + '.tm.fasta')\n",
    "    \n",
    "# #Option 2: File for every cluster that is present in the main data set (and some are redundant)\n",
    "# for prot_fname in os.listdir(pep_seq_dir):\n",
    "#     og_ref = prot_fname.split('.')[0]\n",
    "#     clust = cluster_mapping_dict[og_ref]\n",
    "#     og, clust = clust.split('_')\n",
    "#     shutil.copyfile(clust_align_dir + og+clust + '.fa', clust_align_rename_all_dir + og_ref + '.tm.fasta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a file with each proteome sequence and coding sequence for each item in the MSA\n",
    "\n",
    "#Make big dictionary for selected coding sequences \n",
    "cds_dir = base_dir + os.sep + os.path.normpath('selected_proteins/cds') + os.sep\n",
    "\n",
    "selected_cds_seqs = {}\n",
    "\n",
    "for cds_file in os.listdir(cds_dir):\n",
    "    cds_fasta = SeqIO.parse(cds_dir + cds_file, 'fasta')\n",
    "    for record in cds_fasta: \n",
    "        selected_cds_seqs[record.id] = str(record.seq)\n",
    "\n",
    "#Iterate through each msa \n",
    "tm_align_dir = base_dir + os.sep +  os.path.normpath('msas/structural/tm_align')\n",
    "clust_align_rename_dir = tm_align_dir + os.sep + 'fasta_renamed' + os.sep\n",
    "\n",
    "seq_dir = base_dir + os.sep + 'selected_proteins' + os.sep +  'og_sequences'\n",
    "\n",
    "for msa_file in os.listdir(clust_align_rename_dir):\n",
    "    cds_file_out = seq_dir + os.sep + 'cds_tm' + os.sep + msa_file.split('.')[0] + '.cds.fasta'\n",
    "    pep_file_out = seq_dir + os.sep + 'proteome_tm' + os.sep + msa_file.split('.')[0] + '.pep.fasta'\n",
    "    \n",
    "    msa_file_fasta = SeqIO.parse(clust_align_rename_dir + msa_file, 'fasta')\n",
    "    \n",
    "    with open(cds_file_out,'w') as f_out_cds: \n",
    "        with open(pep_file_out,'w') as f_out_pep:\n",
    "            for record in msa_file_fasta: \n",
    "                 #Squeeze out dashes and record protein sequences\n",
    "                pep_seq = ''.join([res for res in record.seq if res !='-'])\n",
    "                f_out_pep.write('>' + record.id + '\\n')\n",
    "                f_out_pep.write(pep_seq + '\\n') \n",
    "                \n",
    "                #Write CDS sequences\n",
    "                try:\n",
    "                    f_out_cds.write('>' + record.id + '\\n')\n",
    "                    f_out_cds.write(selected_cds_seqs[record.id.split('.')[0]] + '\\n') #Remove .pdb from name\n",
    "                except KeyError:\n",
    "                    print(record.id +  ' cds not found for ' + msa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thread alignments inside inside singularity container\n",
    "#call_code_singularity.sh\n",
    "#which calls /home/heineike_wsl2/github_s/diverse_yeast/20221206_struct_align_dnds_preps.sh\n",
    "#which calls /home/heineike_wsl2/github_s/diverse_yeast/20221206_struct_align_dnds_preps.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Sequence MSAs - also describe structural MSAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code in case we want to go back and do it for Oliver's alignments\n",
    "\n",
    "# #Build a big dictionary for selected coding sequences and make a file for each og_ref name with corresponding cds\n",
    "\n",
    "# #Make a dictionary of coding sequences\n",
    "# cds_dir = base_dir + os.sep + os.path.normpath('selected_proteins/cds') + os.sep\n",
    "\n",
    "# selected_cds_seqs = {}\n",
    "\n",
    "# for cds_file in os.listdir(cds_dir):\n",
    "#     cds_fasta = SeqIO.parse(cds_dir + cds_file, 'fasta')\n",
    "#     for record in cds_fasta: \n",
    "#         selected_cds_seqs[record.id] = str(record.seq)\n",
    "\n",
    "# #Iterate through each msa and make a codon sequence fasta (unaligned)\n",
    "\n",
    "# seq_dir = base_dir + os.sep + 'og_sequences'\n",
    "\n",
    "# for protein_file in os.listdir(seq_dir + os.sep + 'proteome' ):\n",
    "#     cds_file_out = seq_dir + os.sep + 'cds' + os.sep + protein_file.split('.')[0] + '.cds.fasta'\n",
    "    \n",
    "#     protein_file_full = seq_dir + os.sep+ 'proteome' + os.sep + protein_file    \n",
    "#     protein_file_fasta = SeqIO.parse(protein_file_full, 'fasta')\n",
    "    \n",
    "#     with open(cds_file_out,'w') as f_out_cds: \n",
    "#         for record in protein_file_fasta: \n",
    "#             try:\n",
    "#                 f_out_cds.write('>' + record.id + '\\n')\n",
    "#                 f_out_cds.write(selected_cds_seqs[record.id] + '\\n') \n",
    "#             except KeyError:\n",
    "#                 print(record.id +  'cds not found for ' + protein_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is improved above\n",
    "# #Make corresponding codon alignments. \n",
    "\n",
    "# #First make cds lists that contain the same sequences as the clusters\n",
    "# tm_align_dir = base_dir + os.sep +  os.path.normpath('msas/structural/tm_align')\n",
    "# clust_align_rename_dir = tm_align_dir + os.sep + 'fasta_renamed' + os.sep\n",
    "# cds_seq_dir = base_dir + os.sep + os.path.normpath('og_sequences/cds') + os.sep\n",
    "# cds_seq_dir_out = tm_align_dir + os.sep + 'cds' + os.sep\n",
    "\n",
    "\n",
    "\n",
    "# for tm_align_fname in os.listdir(clust_align_rename_dir): \n",
    "#     tm_align = SeqIO.parse(clust_align_rename_dir + tm_align_fname, 'fasta')\n",
    "#     og_ref_base = tm_align_fname.split('.')[0] \n",
    "#     cds_seq_fname = cds_seq_dir + og_ref_base + '.cds.fasta'\n",
    "#     cds_seq = SeqIO.parse(cds_seq_fname, 'fasta')\n",
    "#     cds_seq_lookup = {}\n",
    "#     for record_cds in cds_seq: \n",
    "#         cds_seq_lookup[record_cds.id] = str(record_cds.seq)\n",
    "    \n",
    "#     cds_seq_fname_out = cds_seq_dir_out + og_ref_base + '.tm_present.cds.fasta'\n",
    "#     with open(cds_seq_fname_out, 'w') as f_out:\n",
    "#         for record in tm_align: \n",
    "#             record_id = record.id.split('.')[0]\n",
    "#             try: \n",
    "#                 f_out.write('>' + record_id + '\\n')\n",
    "#                 f_out.write(cds_seq_lookup[record_id] + '\\n')\n",
    "#             except KeyError:\n",
    "#                 print('No cds file for ' + record_id + ' in ' + tm_align_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize phylogenetic trees of orthogroups that are broken apart by clustering with cluster colored in\n",
    "\n",
    "species_table = pd.read_csv(base_dir + os.sep + 'species_selection.csv')\n",
    "species_table_short = species_table.loc[species_table['Load']=='Y', ['original_genome_id', 'jacobs_name']]\n",
    "spec_time_tree_2_orig = dict(zip(species_table_short['jacobs_name'], species_table_short['original_genome_id']))\n",
    "\n",
    "out_image_dir = base_dir + os.sep + os.path.normpath('msas/structural/tm_align/clustering/cluster_trees')+ os.sep\n",
    "\n",
    "\n",
    "ogs_w_subclusters = []\n",
    "for og_clust in list(set(cluster_mapping['og_clust'])): \n",
    "    og, clust = og_clust.split('_')\n",
    "    if clust=='C2': \n",
    "        ogs_w_subclusters.append(og)\n",
    "\n",
    "for og in ogs_w_subclusters: #og = 'OG1004'\n",
    "\n",
    "    cluster_names_og = {}\n",
    "\n",
    "    for cluster in ['C1','C2']: \n",
    "        cluster_names_og[cluster] = [clust_name.split('.')[0] for clust_name in clusters[og+'_' + cluster]]\n",
    "\n",
    "    tree_dir = base_dir + os.sep + 'msas' + os.sep + 'ogs_pep_trees'\n",
    "    fname_tree = tree_dir + os.sep + og + '.mfaa.mafft.clipkit.treefile'\n",
    "    t = Tree(fname_tree, format=0)  \n",
    "    ts = TreeStyle()\n",
    "    ts.show_leaf_name = False\n",
    "    ts.show_branch_length = True\n",
    "\n",
    "    red_node = NodeStyle()\n",
    "    red_node['bgcolor'] = 'red'\n",
    "\n",
    "    blue_node = NodeStyle()\n",
    "    blue_node['bgcolor']= 'LightSteelBlue'\n",
    "\n",
    "\n",
    "    for node in t.traverse(): \n",
    "        if node.is_leaf():\n",
    "            (spec_time_tree, y1000_id) = node.name.split('|')\n",
    "            spec_orig = spec_time_tree_2_orig[spec_time_tree]\n",
    "            if spec_orig in ['saccharomyces_cerevisiae', 'candida_albicans', 'schizosaccaromyces_pombe']:  #probably none in Pombe\n",
    "                print(node.name)\n",
    "            else:\n",
    "                new_name = spec_orig + '__' + og + '__' + y1000_id\n",
    "\n",
    "                if new_name in cluster_names_og['C1']:\n",
    "                    node.set_style(blue_node)\n",
    "                elif new_name in cluster_names_og['C2']: \n",
    "                    node.set_style(red_node)\n",
    "\n",
    "                node.name = new_name\n",
    "                name_face = AttrFace(\"name\",fsize=20)\n",
    "                node.add_face(name_face, column=0, position=\"branch-right\") \n",
    "                #convert name to primary id\n",
    "\n",
    "    t.ladderize()\n",
    "    #t.render('%%inline', tree_style=ts)\n",
    "    t.render(out_image_dir + og + '.pdf', tree_style=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No C2: \n",
    "1603\n",
    "1060 \n",
    "\n",
    "1168 - a lot missing\n",
    "\n",
    "C1 clusters not together: \n",
    "1354, 1394, 1468, 1597, 2071, 2290, 2357 (interesting), 3030, 3104, 3151\n",
    "\n",
    "5735 - how did this pass our filter - not very many sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nir spotted some orthogroups in which Pombe genes are shared in multiple orthogroups\n",
    "\n",
    "OG1\tOG2\n",
    "Spom_AF-Q10142-F1-model_v2.pdb\tOG1242\tOG4624\n",
    "Spom_AF-P55306-F1-model_v2.pdb\t        OG1310\tOG5404\n",
    "Spom_AF-O14192-F1-model_v2.pdb\tOG1377\tOG3639\n",
    "Spom_AF-Q09755-F1-model_v2.pdb\tOG2032\tOG4665\n",
    "Spom_AF-Q09741-F1-model_v2.pdb\tOG2508\tOG3801\n",
    "Spom_AF-O94413-F1-model_v2.pdb\tOG2588\tOG2968\n",
    "Spom_AF-P33075-F1-model_v2.pdb\t        OG2740\tOG5118\n",
    "Spom_AF-Q7LKX0-F1-model_v2.pdb\tOG3021\tOG3909\n",
    "Spom_AF-O13917-F1-model_v2.pdb\tOG4317\tOG4398\n",
    "\n",
    "Oliver sees it is in the og_metadata\n",
    "\n",
    "OGs sharing same pathway (e.g. for the first three)\n",
    "Spom_AF-Q10142-F1-model_v2.pdb\tOG1242\tOG4624\t\t\"['SPHINGOLIPID-SYN-PWY-1']\"\n",
    "Spom_AF-P55306-F1-model_v2.pdb\t       OG1310\tOG5404\t\t\"['DETOX1-PWY']\"\n",
    "Spom_AF-O14192-F1-model_v2.pdb\tOG1377\tOG3639 \t\"['ALL-CHORISMATE-PWY-1', 'COMPLETE-ARO-PWY-1', 'PWY3O-351', 'PWY3O-4108', 'PWY3O-4153']\"\n",
    "\n",
    "\n",
    "S.pombe Q10142 is https://www.uniprot.org/uniprotkb/Q10142/entry\n",
    "AUR1 Ortholog of AUR1 in S.cer\n",
    "\n",
    "OG124 is AUR1 in S.cer\n",
    "\n",
    "OG4624 is IPT1 in S.cer which also looks like a distant ortholog to AUR1\n",
    "\n",
    "http://eggnog5.embl.de/#/app/results?seqid=Q10142&target_nogs=ENOG502QPQM#ENOG5028HC7_datamenu\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model species info\n",
    "\n",
    "#C. albicans\n",
    "#http://www.candidagenome.org/download/sequence/C_albicans_SC5314/Assembly22/current/  \n",
    "# C_albicans_SC5314_A22_current_default_coding.fasta\n",
    "# C_albicans_SC5314_A22_current_default_protein.fasta\n",
    "#downloaded on 20221012 and stored in\n",
    "#G:\\My Drive\\Crick_LMS\\external_data\\genomes\\Candida_albicans\n",
    "\n",
    "\n",
    "#S. cerevisiae\n",
    "#G:\\My Drive\\Crick_LMS\\external_data\\genomes\\Saccharomyces_cerevisiae\\S288C_reference_genome_R64-2-1_20150113\n",
    "#orf_coding_all_R64-2-1_20150113.fasta\n",
    "#orf_trans_all_R64-2-1_20150113.fasta\n",
    "\n",
    "#S. pombe\n",
    "#From https://www.pombase.org/data/genome_sequence_and_features/feature_sequences/ on 20221012\n",
    "#cds.fa \n",
    "#peptide.fa  \n",
    "#both last modified 2022-10-12 03:26\n",
    "#Stored at\n",
    "#G:\\My Drive\\Crick_LMS\\external_data\\genomes\\Schizosaccharomyces_pombe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
